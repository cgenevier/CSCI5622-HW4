{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgenevier/CSCI5622-HW4/blob/part-b-estimation-using-lang-features/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5628e982",
      "metadata": {
        "id": "5628e982"
      },
      "source": [
        "# Study 1: Designing explainable speech-based machine learning models of depression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-KMEnqTjpvj0",
      "metadata": {
        "id": "-KMEnqTjpvj0"
      },
      "source": [
        "To open this ipynb in Colab, click the \"Open in Colab\" button at the top of the ipynb in Github, or [follow this link](https://colab.research.google.com/github/cgenevier/CSCI5622-HW4/blob/main/main.ipynb).\n",
        "\n",
        "Given that Colab doesn't automatically load any of the content (data or other functions) from the Github repo, running the code below will copy the repo into the workspace directory for use. To save this ipynb file back to Github, select **File > Save** (which should show the repo if you're signed in) or **File > Save a copy in Github** if it's in the menu.\n",
        "\n",
        "Note that the content of the data files or any of the other file structures are not saved back to Github, so make sure that if you make changes to things there, that you put them in Github separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QzsrFmmJq1F6",
      "metadata": {
        "id": "QzsrFmmJq1F6"
      },
      "outputs": [],
      "source": [
        "# Clone Github Repo into the temporary local environment so data can be accessed and manipulated\n",
        "!git clone https://github.com/cgenevier/CSCI5622-HW4.git\n",
        "%cd CSCI5622-HW4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FBRtu3JYrGDy",
      "metadata": {
        "id": "FBRtu3JYrGDy"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "# Helpers\n",
        "import glob\n",
        "\n",
        "# Pandas, seaborn, and numpy for data manipulation\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "import statistics as stat\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Keras & TensorFlow for building the neural networks\n",
        "import itertools, json, time\n",
        "from itertools import count\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers, callbacks, backend as K\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Feature extraction\n",
        "!pip install vaderSentiment transformers torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import logging, BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Matplotlib for graphing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Disable progress bars (necessary for it to show up correctly in Github)\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Formatting the data - Depression Labels"
      ],
      "metadata": {
        "id": "3qF5pJFkBPzh"
      },
      "id": "3qF5pJFkBPzh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Depression Labels\n",
        "# Columns: Participant_ID, PHQ_Score\n",
        "depression_labels = pd.read_csv(\"data/DepressionLabels.csv\")\n",
        "\n",
        "# Rename Participant_ID to ParticipantID to match accoustic files below & force trimmed string type\n",
        "depression_labels = depression_labels.rename(columns={\"Participant_ID\": \"ParticipantID\"})\n",
        "depression_labels[\"ParticipantID\"] = depression_labels[\"ParticipantID\"].astype(str).str.strip()"
      ],
      "metadata": {
        "id": "jYBUArPBBVPr"
      },
      "id": "jYBUArPBBVPr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Formatting the data - Text Features"
      ],
      "metadata": {
        "id": "jvoV8lUqBa69"
      },
      "id": "jvoV8lUqBa69"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kesV0RI-rd7I",
      "metadata": {
        "id": "kesV0RI-rd7I"
      },
      "outputs": [],
      "source": [
        "# Import Text Dataset (for text feature extraction)\n",
        "# Note: When comparing the E-DAIC_Transcripts files to the corresponding E-DAIC Acoustics files,\n",
        "# it looks like the transcripts sometimes only contain partial data from the accoustics text column -\n",
        "# for example, 386_Transcript.csv - so it seems to make sense to concatenate Text data in the\n",
        "# Acoustics file for completeness.\n",
        "rows = []\n",
        "for p in glob.glob(\"data/E-DAIC_Acoustics/*_utterance_agg.csv\"):\n",
        "    df = pd.read_csv(p)\n",
        "    df[\"ParticipantID\"] = df[\"ParticipantID\"].astype(str).str.strip()\n",
        "    full_text = \" \".join(df[\"Text\"].dropna().astype(str))\n",
        "    full_text = \" \".join(full_text.split())  # collapse whitespace\n",
        "    rows.append({\"ParticipantID\": df[\"ParticipantID\"].iloc[0], \"FullText\": full_text})\n",
        "\n",
        "# Columns: ParticipantID, FullText\n",
        "text_df = pd.DataFrame(rows)\n",
        "# Merge with labels. Columns: ParticipantID, FullText, PHQ_Score\n",
        "lang_df = depression_labels.merge(text_df, on=\"ParticipantID\", how=\"inner\")\n",
        "\n",
        "# Inspect results\n",
        "lang_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Formatting the data - Acoustic Features"
      ],
      "metadata": {
        "id": "XQzbiWE1Bfmd"
      },
      "id": "XQzbiWE1Bfmd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Accoustic Dataset (for part c, d)\n",
        "\n",
        "# Helper function for mean, standard dev, & IQR (interquartile range)\n",
        "def summarize_cols(num_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # mean and std per column (NaN-safe)\n",
        "    mean_s = num_df.mean(numeric_only=True)\n",
        "    std_s  = num_df.std(numeric_only=True)\n",
        "    # IQR = Q3 - Q1 per column\n",
        "    q75 = num_df.quantile(0.75, numeric_only=True)\n",
        "    q25 = num_df.quantile(0.25, numeric_only=True)\n",
        "    iqr_s = q75 - q25\n",
        "\n",
        "    # assemble into a tidy (feature, stat) table\n",
        "    stats = pd.concat(\n",
        "        {\"mean\": mean_s, \"std\": std_s, \"iqr\": iqr_s},\n",
        "        axis=1\n",
        "    )  # index=feature, columns=[mean,std,iqr]\n",
        "\n",
        "    # flatten to one row with columns like feature__mean\n",
        "    wide = stats.stack().to_frame().T\n",
        "    wide.columns = [f\"{feat}__{stat}\" for feat, stat in wide.columns]\n",
        "    return wide\n",
        "\n",
        "# Each file in E-DAIC_Acoustics contains utterance-level acoustic features for one participant.\n",
        "rows_with_conf = []\n",
        "rows_no_conf = []\n",
        "for p in glob.glob(\"data/E-DAIC_Acoustics/*_utterance_agg.csv\"):\n",
        "    df = pd.read_csv(p)\n",
        "    df[\"ParticipantID\"] = df[\"ParticipantID\"].astype(str).str.strip()\n",
        "\n",
        "    # Include Confidence (column 5) + all acoustic features (6+)\n",
        "    numeric_with_conf = df.columns[5:]\n",
        "    df[numeric_with_conf] = df[numeric_with_conf].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "    agg_with_conf = summarize_cols(df[numeric_with_conf])\n",
        "    agg_with_conf.insert(0, \"ParticipantID\", df[\"ParticipantID\"].iloc[0])\n",
        "    rows_with_conf.append(agg_with_conf)\n",
        "\n",
        "    # Excludes Confidence - only include acoustic features\n",
        "    numeric_no_conf = df.columns[6:]\n",
        "    df[numeric_no_conf] = df[numeric_no_conf].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "    agg_no_conf = summarize_cols(df[numeric_no_conf])\n",
        "    agg_no_conf.insert(0, \"ParticipantID\", df[\"ParticipantID\"].iloc[0])\n",
        "    rows_no_conf.append(agg_no_conf)\n",
        "\n",
        "# Combine into one DataFrame each\n",
        "acoustic_features_with_conf = pd.concat(rows_with_conf, ignore_index=True)\n",
        "acoustic_features_no_conf = pd.concat(rows_no_conf, ignore_index=True)\n",
        "\n",
        "# Merge with labels to add PHQ_Score\n",
        "acoustic_df_with_confidence = depression_labels.merge(acoustic_features_with_conf, on=\"ParticipantID\", how=\"inner\")\n",
        "acoustic_df_no_confidence   = depression_labels.merge(acoustic_features_no_conf, on=\"ParticipantID\", how=\"inner\")\n",
        "\n",
        "# Reorder columns: ParticipantID, PHQ_Score, then features\n",
        "cols = [\"ParticipantID\", \"PHQ_Score\"] + [c for c in acoustic_df_with_confidence.columns if c not in [\"ParticipantID\", \"PHQ_Score\"]]\n",
        "acoustic_df_with_confidence = acoustic_df_with_confidence[cols]\n",
        "cols = [\"ParticipantID\", \"PHQ_Score\"] + [c for c in acoustic_df_no_confidence.columns if c not in [\"ParticipantID\", \"PHQ_Score\"]]\n",
        "acoustic_df_no_confidence = acoustic_df_no_confidence[cols]\n",
        "\n",
        "# Inspect results\n",
        "display(acoustic_df_with_confidence.head())\n",
        "display(acoustic_df_no_confidence.head())"
      ],
      "metadata": {
        "id": "o8gRSINXBmUJ"
      },
      "id": "o8gRSINXBmUJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bb4bfe84",
      "metadata": {
        "id": "bb4bfe84"
      },
      "source": [
        "### (a) (2 points) Extracting language features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cc1fb7",
      "metadata": {
        "id": "c7cc1fb7"
      },
      "source": [
        "**Syntactic vectorizers:** count vectorizer (e.g., CountVectorizer from sklearn) transforming\n",
        "a collection of text documents into a numerical matrix of word or token counts; TFIDF vectorizer (e.g., TfidfVectorizer from sklearn) incorporating document-level weighting,\n",
        "which emphasizes words significant to specific documentsâ€™ part-of-speech features counting\n",
        "the distribution of part of speech tags over a document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd57d88c",
      "metadata": {
        "id": "dd57d88c"
      },
      "outputs": [],
      "source": [
        "# Use TfidfVectorizer from sklearn\n",
        "vect = TfidfVectorizer(max_features=1000)\n",
        "X_tfidf = vect.fit_transform(lang_df[\"FullText\"])\n",
        "\n",
        "# Convert sparse matrix to DataFrame\n",
        "syntactic_df = pd.DataFrame(\n",
        "    X_tfidf.toarray(),\n",
        "    columns=vect.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Add ParticipantID column & move to first column\n",
        "syntactic_df[\"ParticipantID\"] = lang_df[\"ParticipantID\"].values\n",
        "cols = [\"ParticipantID\"] + [c for c in syntactic_df.columns if c != \"ParticipantID\"]\n",
        "syntactic_df = syntactic_df[cols]\n",
        "\n",
        "# Add back in PHQ_Score & move to second column\n",
        "syntactic_df = syntactic_df.merge(depression_labels, on=\"ParticipantID\", how=\"inner\")\n",
        "cols = [\"ParticipantID\", \"PHQ_Score\"] + [c for c in syntactic_df.columns if c not in [\"ParticipantID\", \"PHQ_Score\"]]\n",
        "syntactic_df = syntactic_df[cols]\n",
        "\n",
        "# Inspect dataframe\n",
        "syntactic_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4662aca0",
      "metadata": {
        "id": "4662aca0"
      },
      "source": [
        "**Semantic features:** sentiment scores (e.g., Vader, https://github.com/cjhutto/vaderSentiment),\n",
        "topic distribution (using topic modeling), or named entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb764609",
      "metadata": {
        "id": "fb764609"
      },
      "outputs": [],
      "source": [
        "# Using Vader to analyze sentiment of the text data\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Apply Vader to the text data (creates 4 new columns)\n",
        "vader_scores = lang_df[\"FullText\"].apply(lambda x: pd.Series(analyzer.polarity_scores(str(x))))\n",
        "semantic_df = pd.concat([lang_df, vader_scores], axis=1)\n",
        "\n",
        "# Inspect dataframe\n",
        "semantic_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16a6fd00",
      "metadata": {
        "id": "16a6fd00"
      },
      "source": [
        "**Advanced features:** word embeddings, such as Word2Vec or BERT (e.g., pytorch-pretrainedbert)) for capturing contextual meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4a1f0a",
      "metadata": {
        "id": "8a4a1f0a"
      },
      "outputs": [],
      "source": [
        "# Use BERT to capture contextual meaning (note: takes about 4 minutes to run on T4)\n",
        "\n",
        "# Load uncased base model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "model.eval()\n",
        "\n",
        "# Loop through text data and get embeddings\n",
        "embeddings = []\n",
        "for text in lang_df[\"FullText\"]:\n",
        "    # Truncate long text (BERT max = 512 tokens)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # [CLS] token\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# Convert list of embeddings (each 768-dim) to DataFrame\n",
        "bert_df = pd.DataFrame(np.vstack(embeddings))\n",
        "bert_df.columns = [f\"bert_{i}\" for i in range(bert_df.shape[1])]\n",
        "\n",
        "# Add ParticipantID and PHQ_Score\n",
        "bert_df = pd.concat([lang_df[[\"ParticipantID\", \"PHQ_Score\"]].reset_index(drop=True), bert_df], axis=1)\n",
        "\n",
        "# Inspect dataframe\n",
        "bert_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined dataset:** Combined the three dataframes above into one with all the features"
      ],
      "metadata": {
        "id": "6wo7ZsVkGs2R"
      },
      "id": "6wo7ZsVkGs2R"
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all three on ParticipantID\n",
        "text_feature_df = (\n",
        "    syntactic_df\n",
        "    .merge(semantic_df, on=[\"ParticipantID\", \"PHQ_Score\"], how=\"outer\")\n",
        "    .merge(bert_df, on=[\"ParticipantID\", \"PHQ_Score\"], how=\"outer\")\n",
        ")\n",
        "text_feature_df.head()\n",
        "\n",
        "# Optional: sort by ParticipantID for clarity\n",
        "#merged_df = merged_df.sort_values(\"ParticipantID\").reset_index(drop=True)"
      ],
      "metadata": {
        "id": "uk3qdhqGGzo6"
      },
      "id": "uk3qdhqGGzo6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9be58d95",
      "metadata": {
        "id": "9be58d95"
      },
      "source": [
        "### (b) (2 points) Estimating depression severity with interpretable models using language features."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: In semantic feature extraction above, there are four features generated: neg, neu, pos, compound. They are inter-related because neg is the proportion of the document that is negative, neu is the proportion of the document that is neutral, pos is the proportion of the document that is positive, and compound is a normalized sentiment value that takes into account all 3. Should we remove some of these features because they're redundant?"
      ],
      "metadata": {
        "id": "6tZemAZTQCAy"
      },
      "id": "6tZemAZTQCAy"
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Part (b): Estimating depression severity using language (VADER) features -------- #\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "\n",
        "# Language features extracted in Part (a)\n",
        "lang_features = [\"neg\", \"neu\", \"pos\", \"compound\"]\n",
        "\n",
        "# Only keep valid rows\n",
        "df_b = semantic_df.dropna(subset=[\"PHQ_Score\"])\n",
        "\n",
        "X = df_b[lang_features].values\n",
        "y = df_b[\"PHQ_Score\"].values\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Test different values of k (tree depth)\n",
        "for k in [2, 3, 4, 5, 6]:\n",
        "    all_preds = []\n",
        "    all_truth = []\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Decision tree with varying depth k\n",
        "        model = DecisionTreeRegressor(max_depth=k, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        preds = model.predict(X_test)\n",
        "        all_preds.extend(preds)\n",
        "        all_truth.extend(y_test)\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_truth = np.array(all_truth)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    r, _ = pearsonr(all_preds, all_truth)\n",
        "    RE = np.mean(np.abs(all_preds - all_truth) / np.max(all_truth))\n",
        "\n",
        "    results.append({\"k\": k, \"Pearson_r\": r, \"RE\": RE})\n",
        "\n",
        "# Show results table\n",
        "results_df = pd.DataFrame(results)\n",
        "display(results_df)\n",
        "\n",
        "# Train final model with best k (optional)\n",
        "best_k = results_df.iloc[results_df[\"Pearson_r\"].idxmax()][\"k\"]\n",
        "print(\"\\nBest k based on Pearson r:\", best_k)\n"
      ],
      "metadata": {
        "id": "RycC0ndwzhdH"
      },
      "id": "RycC0ndwzhdH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e6a8a6a4",
      "metadata": {
        "id": "e6a8a6a4"
      },
      "source": [
        "### (c) (2 points) Estimating depression severity with interpretable models using acoustic features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cea9a9b",
      "metadata": {
        "id": "2cea9a9b"
      },
      "source": [
        "### (d) (2 points) Estimating depression severity with unimodal and multimodal deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: In semantic feature extraction above, there are four features generated: neg, neu, pos, compound. They are inter-related because neg is the proportion of the document that is negative, neu is the proportion of the document that is neutral, pos is the proportion of the document that is positive, and compound is a normalized sentiment value that takes into account all 3. Should we remove some of these features because they're redundant?"
      ],
      "metadata": {
        "id": "TifQHM_8QX1Q"
      },
      "id": "TifQHM_8QX1Q"
    },
    {
      "cell_type": "markdown",
      "id": "4299e73c",
      "metadata": {
        "id": "4299e73c"
      },
      "source": [
        "### (e) (2 points) Explainable ML."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32cd773d",
      "metadata": {
        "id": "32cd773d"
      },
      "source": [
        "### (f) (Bonus, 2 points) Experimenting with transformers."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2ffc3e8",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgenevier/CSCI5622-HW4/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5628e982",
      "metadata": {
        "id": "5628e982"
      },
      "source": [
        "# Study 1: Designing explainable speech-based machine learning models of depression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-KMEnqTjpvj0",
      "metadata": {
        "id": "-KMEnqTjpvj0"
      },
      "source": [
        "To open this ipynb in Colab, click the \"Open in Colab\" button at the top of the ipynb in Github, or [follow this link](https://colab.research.google.com/github/cgenevier/CSCI5622-HW4/blob/main/main.ipynb).\n",
        "\n",
        "Given that Colab doesn't automatically load any of the content (data or other functions) from the Github repo, running the code below will copy the repo into the workspace directory for use. To save this ipynb file back to Github, select **File > Save** (which should show the repo if you're signed in) or **File > Save a copy in Github** if it's in the menu.\n",
        "\n",
        "Note that the content of the data files or any of the other file structures are not saved back to Github, so make sure that if you make changes to things there, that you put them in Github separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "QzsrFmmJq1F6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzsrFmmJq1F6",
        "outputId": "b9301f7f-7da8-4b8e-b27f-229cbd59ca95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CSCI5622-HW4'...\n",
            "remote: Enumerating objects: 400, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (398/398), done.\u001b[K\n",
            "^Cceiving objects:  22% (88/400), 1.44 MiB | 2.83 MiB/s\n",
            "[Errno 2] No such file or directory: 'CSCI5622-HW4'\n",
            "/Library/WebServer/Sites/School/CSCI5622-HW4\n"
          ]
        }
      ],
      "source": [
        "# Clone Github Repo into the temporary local environment so data can be accessed and manipulated\n",
        "!git clone https://github.com/cgenevier/CSCI5622-HW4.git\n",
        "%cd CSCI5622-HW4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "FBRtu3JYrGDy",
      "metadata": {
        "id": "FBRtu3JYrGDy"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "# Helpers\n",
        "import glob\n",
        "\n",
        "# Pandas, seaborn, and numpy for data manipulation\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "import statistics as stat\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Keras & TensorFlow for building the neural networks\n",
        "import itertools, json, time\n",
        "from itertools import count\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers, callbacks, backend as K\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Feature extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Matplotlib for graphing\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "kesV0RI-rd7I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kesV0RI-rd7I",
        "outputId": "0f8f1acf-181e-4b30-a91d-d02e46ff38cc"
      },
      "outputs": [],
      "source": [
        "# Import Depression Labels\n",
        "# Columns: Participant_ID, PHQ_Score \n",
        "depression_labels = pd.read_csv(\"data/DepressionLabels.csv\")\n",
        "\n",
        "# Rename Participant_ID to ParticipantID to match accoustic files below & force trimmed string type\n",
        "depression_labels = depression_labels.rename(columns={\"Participant_ID\": \"ParticipantID\"})\n",
        "depression_labels[\"ParticipantID\"] = depression_labels[\"ParticipantID\"].astype(str).str.strip()\n",
        "\n",
        "# Import Text Dataset (for text feature extraction)\n",
        "# Note: When comparing the E-DAIC_Transcripts files to the corresponding E-DAIC Acoustics files, \n",
        "# it looks like the transcripts sometimes only contain partial data from the accoustics text column -\n",
        "# for example, 386_Transcript.csv - so it seems to make sense to concatenate Text data in the \n",
        "# Acoustics file for completeness.\n",
        "rows = []\n",
        "for p in glob.glob(\"data/E-DAIC_Acoustics/*_utterance_agg.csv\"):\n",
        "    df = pd.read_csv(p)\n",
        "    df[\"ParticipantID\"] = df[\"ParticipantID\"].astype(str).str.strip()\n",
        "    full_text = \" \".join(df[\"Text\"].dropna().astype(str))\n",
        "    full_text = \" \".join(full_text.split())  # collapse whitespace\n",
        "    rows.append({\"ParticipantID\": df[\"ParticipantID\"].iloc[0], \"FullText\": full_text})\n",
        "\n",
        "# Columns: ParticipantID, FullText\n",
        "text_df = pd.DataFrame(rows)\n",
        "# Merge with labels. Columns: ParticipantID, FullText, PHQ_Score\n",
        "lang_df = depression_labels.merge(text_df, on=\"ParticipantID\", how=\"inner\")\n",
        "\n",
        "\n",
        "# Import Accoustic Dataset (for part c, d)\n",
        "# Note: May need to aggregate the data per participant, ex: mean, std, iqr for each feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb4bfe84",
      "metadata": {
        "id": "bb4bfe84"
      },
      "source": [
        "### (a) (2 points) Extracting language features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cc1fb7",
      "metadata": {},
      "source": [
        "**Syntactic vectorizers:** count vectorizer (e.g., CountVectorizer from sklearn) transforming\n",
        "a collection of text documents into a numerical matrix of word or token counts; TFIDF vectorizer (e.g., TfidfVectorizer from sklearn) incorporating document-level weighting,\n",
        "which emphasizes words significant to specific documents’ part-of-speech features counting\n",
        "the distribution of part of speech tags over a document "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dd57d88c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ParticipantID</th>\n",
              "      <th>PHQ_Score</th>\n",
              "      <th>10</th>\n",
              "      <th>12</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>...</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yet</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngest</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>386</td>\n",
              "      <td>11</td>\n",
              "      <td>0.008627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.352474</td>\n",
              "      <td>0.011232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016914</td>\n",
              "      <td>0.019322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387</td>\n",
              "      <td>2</td>\n",
              "      <td>0.027755</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047486</td>\n",
              "      <td>0.346512</td>\n",
              "      <td>0.072275</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.108838</td>\n",
              "      <td>0.031083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>388</td>\n",
              "      <td>17</td>\n",
              "      <td>0.031186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283166</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020382</td>\n",
              "      <td>0.034926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>389</td>\n",
              "      <td>14</td>\n",
              "      <td>0.054573</td>\n",
              "      <td>0.052964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.325182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.089168</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>390</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016775</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008948</td>\n",
              "      <td>0.020119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.123706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.009498</td>\n",
              "      <td>0.016275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  ParticipantID  PHQ_Score        10        12   15   16   18   19        20  \\\n",
              "0           386         11  0.008627  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
              "1           387          2  0.027755  0.000000  0.0  0.0  0.0  0.0  0.032038   \n",
              "2           388         17  0.031186  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
              "3           389         14  0.054573  0.052964  0.0  0.0  0.0  0.0  0.000000   \n",
              "4           390          9  0.000000  0.000000  0.0  0.0  0.0  0.0  0.016775   \n",
              "\n",
              "    30  ...       yes  yesterday       yet      york       you     young  \\\n",
              "0  0.0  ...  0.010623   0.000000  0.000000  0.000000  0.352474  0.011232   \n",
              "1  0.0  ...  0.000000   0.000000  0.000000  0.047486  0.346512  0.072275   \n",
              "2  0.0  ...  0.038404   0.000000  0.040133  0.000000  0.283166  0.000000   \n",
              "3  0.0  ...  0.000000   0.000000  0.000000  0.000000  0.325182  0.000000   \n",
              "4  0.0  ...  0.008948   0.020119  0.000000  0.000000  0.123706  0.000000   \n",
              "\n",
              "   younger  youngest      your  yourself  \n",
              "0      0.0       0.0  0.016914  0.019322  \n",
              "1      0.0       0.0  0.108838  0.031083  \n",
              "2      0.0       0.0  0.020382  0.034926  \n",
              "3      0.0       0.0  0.089168  0.000000  \n",
              "4      0.0       0.0  0.009498  0.016275  \n",
              "\n",
              "[5 rows x 1002 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use TfidfVectorizer from sklearn\n",
        "vect = TfidfVectorizer(max_features=1000)\n",
        "X_tfidf = vect.fit_transform(lang_df[\"FullText\"])\n",
        "\n",
        "# Convert sparse matrix to DataFrame\n",
        "tfidf_df = pd.DataFrame(\n",
        "    X_tfidf.toarray(),\n",
        "    columns=vect.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Add ParticipantID column & move to first column\n",
        "tfidf_df[\"ParticipantID\"] = lang_df[\"ParticipantID\"].values\n",
        "cols = [\"ParticipantID\"] + [c for c in tfidf_df.columns if c != \"ParticipantID\"]\n",
        "tfidf_df = tfidf_df[cols]\n",
        "\n",
        "# Add back in PHQ_Score & move to second column\n",
        "tfidf_df = tfidf_df.merge(depression_labels, on=\"ParticipantID\", how=\"inner\")\n",
        "cols = [\"ParticipantID\", \"PHQ_Score\"] + [c for c in tfidf_df.columns if c not in [\"ParticipantID\", \"PHQ_Score\"]]\n",
        "tfidf_df = tfidf_df[cols]\n",
        "\n",
        "# Inspect dataframe\n",
        "tfidf_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4662aca0",
      "metadata": {},
      "source": [
        "**Semantic features:** sentiment scores (e.g., Vader, https://github.com/cjhutto/vaderSentiment),\n",
        "topic distribution (using topic modeling), or named entities "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb764609",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "16a6fd00",
      "metadata": {},
      "source": [
        "**Advanced features:** word embeddings, such as Word2Vec or BERT (e.g., pytorch-pretrainedbert)) for capturing contextual meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4a1f0a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9be58d95",
      "metadata": {
        "id": "9be58d95"
      },
      "source": [
        "### (b) (2 points) Estimating depression severity with interpretable models using language features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a8a6a4",
      "metadata": {
        "id": "e6a8a6a4"
      },
      "source": [
        "### (c) (2 points) Estimating depression severity with interpretable models using acoustic features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cea9a9b",
      "metadata": {
        "id": "2cea9a9b"
      },
      "source": [
        "### (d) (2 points) Estimating depression severity with unimodal and multimodal deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4299e73c",
      "metadata": {
        "id": "4299e73c"
      },
      "source": [
        "### (e) (2 points) Explainable ML."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32cd773d",
      "metadata": {
        "id": "32cd773d"
      },
      "source": [
        "### (f) (Bonus, 2 points) Experimenting with transformers."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
